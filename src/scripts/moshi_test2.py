import sounddevice as sd
import torch
from transformers import AutoModelForCausalLM
import os

# ===== â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜… =====
# rustymimiã®ä»£ã‚ã‚Šã«ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®audio_codec.pyã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™
# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª(/workspace/src)ã‹ã‚‰å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
from jmvis.utils.audio_codec import encode as audio_encode, decode as audio_decode
# ==============================

moshi_name = "kyutai/moshiko-pytorch-bf16"
device = "cuda" if torch.cuda.is_available() else "cpu"

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
model = AutoModelForCausalLM.from_pretrained(
    moshi_name,
    torch_dtype=torch.float16,
    device_map="auto"
).eval()

# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®š
sr = 16000
# Moshiã®å†…éƒ¨å‡¦ç†ã¯24kHzã§ã™ãŒã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒ16kHzã‚’æœŸå¾…ã™ã‚‹ãŸã‚ã“ã®ã¾ã¾ã§OK
block_size = 1024
context = torch.tensor([], dtype=torch.long, device=device).unsqueeze(0)

def callback(indata, frames, time, status):
    global context
    if status:
        print(status)
    
    # éŸ³å£°ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
    audio_tensor = torch.tensor(indata[:, 0], dtype=torch.float32)
    tokens = audio_encode(audio_tensor) # ä¿®æ­£ã—ãŸé–¢æ•°åã‚’ä½¿ç”¨
    
    if not tokens:
        return

    tokens = torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0)
    context = torch.cat([context, tokens], dim=1)

    # é•·ã™ãã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šæ¨ã¦ã‚‹ï¼ˆä¾‹ã¨ã—ã¦éå»4096ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿æŒï¼‰
    if context.shape[1] > 4096:
        context = context[:, -4096:]

    # ãƒ¢ãƒ‡ãƒ«ã«é€æ¬¡å…¥åŠ›
    with torch.no_grad():
        # model.generateã‚’ä½¿ç”¨ã—ã¦ã€ã‚ˆã‚Šå®‰å®šã—ãŸå‡ºåŠ›ã‚’å¾—ã‚‹
        outputs = model.generate(context, max_new_tokens=1, do_sample=False)
        pred_token = outputs[0, -1].item()
        
    # äºˆæ¸¬ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
    pred_token_tensor = torch.tensor([[pred_token]], dtype=torch.long, device=device)
    context = torch.cat([context, pred_token_tensor], dim=1)

    # éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã«å‡ºåŠ›
    out_wav_tensor = audio_decode([pred_token]) # ä¿®æ­£ã—ãŸé–¢æ•°åã‚’ä½¿ç”¨
    if out_wav_tensor.numel() > 0:
        sd.play(out_wav_tensor.squeeze(0).cpu().numpy(), sr)

# ãƒã‚¤ã‚¯å…¥åŠ›ã‚’é–‹å§‹
try:
    # æ—¢å­˜ã®rustymimiã‚’ã‚¢ãƒ³ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå¿µã®ãŸã‚ï¼‰
    print("æ—¢å­˜ã®rustymimiã‚’ã‚¢ãƒ³ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã‚ˆã†ã¨è©¦ã¿ã¾ã™ï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç„¡è¦–ã•ã‚Œã¾ã™ï¼‰...")
    os.system("pip uninstall -y rustymimi")
    
    print("\nğŸ¤ ãƒã‚¤ã‚¯ã«å‘ã‹ã£ã¦è©±ã—ã¦ãã ã•ã„ (Ctrl+Cã§åœæ­¢)")
    with sd.InputStream(channels=1, samplerate=sr, blocksize=block_size, callback=callback):
        import time
        while True:
            time.sleep(0.1)
except KeyboardInterrupt:
    print("\nã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
except Exception as e:
    print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    print("\nPyAudioã¾ãŸã¯PortAudioãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    print("Ubuntu/Debianã®å ´åˆ: sudo apt-get install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0")
    print("condaã®å ´åˆ: conda install pyaudio")