import os
import torch
import hydra
from omegaconf import DictConfig, OmegaConf
from accelerate import Accelerator
from huggingface_hub import hf_hub_download
import sentencepiece as spm
from tqdm import tqdm

# jmvis ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„)
from moshi.models.loaders import get_mimi
from jmoshivis.models.loaders import get_moshi_vis_train
from jmoshivis.datasets.interleaver import InterleavedTokenizer, Interleaver
from jmoshivis.datasets.data_loader import build_data_loader
from jmoshivis.distributed import get_rank, get_world_size
from jmoshivis.config.kyuteye_config import KyuteyeConfig

@hydra.main(version_base=None, config_path="../configs", config_name="config")
def main(args: DictConfig):
    # åˆ†æå¯¾è±¡ã® Duration ãƒªã‚¹ãƒˆ (ç§’)
    durations = [10, 100]
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    accelerator = Accelerator(mixed_precision="bf16")
    
    # ã‚³ãƒ³ãƒ•ã‚£ã‚°ã®ãƒ‘ã‚¹ã¯ç’°å¢ƒã«åˆã‚ã›ã¦ä¿®æ­£ã—ã¦ãã ã•ã„
    config_path = "/workspace/j-moshivis/configs/j-moshi-vis.yaml"
    if os.path.exists(config_path):
        kyuteye_config = KyuteyeConfig.from_yml(config_path)
    else:
        print(f"Warning: Config not found at {config_path}. Using default or args.")
        # å¿…è¦ã«å¿œã˜ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        return

    # --- Tokenizer / Processor ---
    tokenizer_path = "/workspace/j-moshivis/jmoshivis/tokenizer_spm_32k_3.model"
    tokenizer = spm.SentencePieceProcessor()
    tokenizer.load(tokenizer_path)

    if accelerator.is_main_process:
        print("Loading Mimi and MoshiVis...")
    
    # Mimi ã®ãƒ­ãƒ¼ãƒ‰
    mimi_weight = hf_hub_download(
        repo_id=args.repo_id,
        filename=args.mimi_name,
    )
    mimi = get_mimi(mimi_weight, device)
    mimi.eval()
    for p in mimi.parameters():
        p.requires_grad = False

    # MoshiVis ã®ãƒ­ãƒ¼ãƒ‰
    print("Start get_moshi_vis_train")
    moshi_vis, image_embedder = get_moshi_vis_train(
        kyuteye_config=kyuteye_config,
        moshivis_weight="/workspace/j-moshivis/model_merged_bf16.safetensors",
        device=device,
        dtype=torch.bfloat16,
        strict=False,
        freeze_backbone=True,
    )

    # PADãƒˆãƒ¼ã‚¯ãƒ³IDã®å–å¾—
    pad_token_id = moshi_vis.text_padding_token_id
    print(f"Text Padding Token ID: {pad_token_id}")

    print("\n" + "="*60)
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³åˆ†æé–‹å§‹")
    print("="*60)

    results = []

    # å„ Duration è¨­å®šã§ãƒ«ãƒ¼ãƒ—
    for duration_sec in durations:
        if accelerator.is_main_process:
            print(f"\nAnalyzing for Duration: {duration_sec} seconds...")

        # Interleaver ã®å†æ§‹ç¯‰ (duration ã«ä¾å­˜ã—ãªã„éƒ¨åˆ†ã¯å¤–ã§ã‚‚è‰¯ã„ãŒå¿µã®ãŸã‚)
        interleaver = Interleaver(
            tokenizer,
            mimi.frame_rate,
            moshi_vis.text_padding_token_id,
            moshi_vis.end_of_text_padding_id,
            moshi_vis.zero_token_id,
            keep_main_only=True,
            device=device,
        )
        
        # InterleavedTokenizer ã®æ§‹ç¯‰ (duration ã‚’æ›´æ–°)
        interleaved_tokenizer = InterleavedTokenizer(
            mimi, interleaver, duration_sec=duration_sec
        )

        target_len = int(mimi.frame_rate * duration_sec)
        
        # DataLoader ã®æ§‹ç¯‰
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯VRAMã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„ (åˆ†æç”¨ãªã®ã§å¤§ãã‚ã§ã‚‚å¯)
        analyze_batch_size = args.train.batch_size
        
        data_loader = build_data_loader(
            instruct_tokenizer=interleaved_tokenizer,
            args=args.data,
            batch_size=analyze_batch_size,
            seed=args.train.seed,
            rank=get_rank(),
            world_size=get_world_size(),
            is_eval=True,
            image_root=args.data.image_root,
            image_embedder=image_embedder,
            device=device,
            mode="speech",
            text_tokenizer=tokenizer,
            target_len=target_len
        )

        total_valid_tokens = 0  # åˆ†æ¯: -1ä»¥å¤–ã®ãƒˆãƒ¼ã‚¯ãƒ³ç·æ•°
        total_pad_tokens = 0    # åˆ†å­: æœ‰åŠ¹ç¯„å›²å†…ã®PADãƒˆãƒ¼ã‚¯ãƒ³æ•°
        total_samples = 0

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèµ°æŸ»
        for batch in tqdm(data_loader, desc=f"Dur {duration_sec}s", disable=not accelerator.is_main_process):
            # batch.codes shape: [B, D, T]
            # Moshiã®ä»•æ§˜ã§ã¯ Codebook 0 ãŒãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ (Vocabulary size ~32k)
            # Codebook 1-16 ãŒéŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ (Vocabulary size 2048)
            
            codes = batch.codes.to(device)
            text_codes = codes[:, 0, :]  # [B, T]
            
            # --- ä¿®æ­£ç®‡æ‰€: -1 (ç„¡åŠ¹ãªãƒ‘ãƒ‡ã‚£ãƒ³ã‚°) ã‚’é™¤å¤–ã—ã¦è¨ˆç®— ---
            ignore_token_id = -1

            # -1 ä»¥å¤–ã®éƒ¨åˆ†ã‚’æœ‰åŠ¹ã¨ã™ã‚‹ãƒã‚¹ã‚¯ã‚’ä½œæˆ
            valid_mask = (text_codes != ignore_token_id)

            # åˆ†æ¯: æœ‰åŠ¹ãªãƒˆãƒ¼ã‚¯ãƒ³æ•° (-1 ä»¥å¤–)
            num_valid = valid_mask.sum().item()

            # åˆ†å­: æœ‰åŠ¹ãªç¯„å›²å†…ã§ã€ã‹ã¤ PADãƒˆãƒ¼ã‚¯ãƒ³ (ID: 3) ã§ã‚ã‚‹ã‚‚ã®
            # è«–ç†ç© (&) ã‚’å–ã‚‹ã“ã¨ã§ã€ä¸‡ãŒä¸€ -1 ã®åŸ‹ã‚è‰éƒ¨åˆ†ã« 3 ãŒå…¥ã£ã¦ã„ã¦ã‚‚ã‚«ã‚¦ãƒ³ãƒˆã—ãªã„ã‚ˆã†ã«ã™ã‚‹
            num_pads = ((text_codes == pad_token_id) & valid_mask).sum().item()
            
            total_valid_tokens += num_valid
            total_pad_tokens += num_pads
            total_samples += codes.shape[0]

        # çµæœé›†è¨ˆ
        if total_valid_tokens > 0:
            pad_ratio = (total_pad_tokens / total_valid_tokens) * 100
            result_str = (
                f"Duration: {duration_sec:3}s | "
                f"Valid Tokens: {total_valid_tokens:12,} | "
                f"PAD Tokens: {total_pad_tokens:12,} | "
                f"PAD Ratio: {pad_ratio:.2f}% (excluding -1 padding)"
            )
            results.append(result_str)
            if accelerator.is_main_process:
                print(f"ğŸ‘‰ {result_str}")
        else:
            if accelerator.is_main_process:
                print(f"âš ï¸ Duration {duration_sec}s: No valid tokens found.")

    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    if accelerator.is_main_process:
        print("\n" + "="*60)
        print("ğŸ“‘ æœ€çµ‚åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*60)
        for res in results:
            print(res)
        print("="*60)

if __name__ == "__main__":
    main()