# Copyright (c) Kyutai, all rights reserved.
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.

"""Load moshi-vis neccessary components."""

from typing import Any, Dict, Optional, Tuple

import torch
from safetensors.torch import load_file

from jmoshivis.config.kyuteye_config import KyuteyeConfig
from jmoshivis.models.image_projection import ImageProjection
from jmoshivis.models.moshivis import MoshiVisGen, MoshiVis


def get_moshi_vis(
    kyuteye_config: KyuteyeConfig,
    moshi_weight: Optional[str] = None,
    device: str | torch.device = "cpu",
    dtype: torch.dtype = torch.bfloat16,
    gen_kwargs: Optional[Dict[str, Any]] = None,
) -> Tuple[MoshiVisGen, ImageProjection]:
    """Return main Moshi model"""
    image_proj_state: Dict[str, torch.Tensor] = {}
    model_state: Dict[str, torch.Tensor] = {}

    if moshi_weight is not None:
        from safetensors.torch import load_file
        loaded_weights = load_file(moshi_weight, device="cpu")

        # =========================================================
        # ğŸ” ãƒ‡ãƒãƒƒã‚°: ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ã‚­ãƒ¼åã‚’ç¢ºèª (æœ€åˆã®50å€‹)
        # =========================================================
        print("\nğŸ” [DEBUG] File Keys Preview (First 50):")
        all_file_keys = list(loaded_weights.keys())
        for k in all_file_keys[:50]:
            print(f"  - {k}")
        
        # ç‰¹ã«Cross-Attentioné–¢é€£ã®ã‚­ãƒ¼ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤º
        print("\nğŸ” [DEBUG] Cross-Attention Keys in File:")
        ca_keys = [k for k in all_file_keys if "cross_attention" in k]
        if ca_keys:
            for k in ca_keys[:20]: # é•·ã„ã®ã§æœ€åˆã®20å€‹
                print(f"  - {k}")
        else:
            print("  âŒ No cross_attention keys found!")
        print("=========================================================\n")

        for key, v in load_file(moshi_weight, device=device).items():  # type: ignore
            clean_key = key
            is_image_proj = False

            # 1. "image_prefix." ã®å‡¦ç†
            if clean_key.startswith("image_prefix."):
                clean_key = clean_key[len("image_prefix."):]
                is_image_proj = True
            
            # 2. "module." ã®å¼·åˆ¶å‰Šé™¤ (ã“ã‚ŒãŒä»Šå›ã®è‚)
            if clean_key.startswith("module."):
                clean_key = clean_key[len("module."):]

            # 3. "_orig_mod." (torch.compileç”±æ¥) ã‚‚å¿µã®ãŸã‚å‰Šé™¤
            if clean_key.startswith("_orig_mod."):
                clean_key = clean_key[len("_orig_mod."):]

            # 4. æŒ¯ã‚Šåˆ†ã‘
            if is_image_proj:
                image_proj_state[clean_key] = v
            else:
                model_state[clean_key] = v

    print("ğŸ” Num image_prefix params:", len(image_proj_state))
    print("ğŸ” Example keys:", list(image_proj_state.keys())[:10])

    moshi_vis = MoshiVisGen.from_config(
        kyuteye_config, model_state, device, dtype, **(gen_kwargs or {})
    )
    image_embedder = ImageProjection.from_config(
        kyuteye_config, moshi_vis.model_dim, image_proj_state, device
    )

    # --- 2. å³å¯†ãªãƒ­ãƒ¼ãƒ‰ç¢ºèª (Verification) ---
    print("\nğŸ” --- Weight Loading Verification ---")

    # (A) Image Embedder ã® Projectionå±¤
    # SigLIP (enc.model...) ã ã‘ã§ãªãã€å­¦ç¿’ã•ã›ãŸ projection (proj, linearãªã©) ãŒã‚ã‚‹ã‹ï¼Ÿ
    embedder_keys = set(image_embedder.state_dict().keys())
    loaded_embedder_keys = set(image_proj_state.keys())
    
    # å¿…é ˆãƒã‚§ãƒƒã‚¯: "proj" ã¾ãŸã¯ "linear" ã‚’å«ã‚€å±¤ï¼ˆå®Ÿè£…ä¾å­˜ã ãŒé€šå¸¸å­˜åœ¨ã™ã‚‹ã¯ãšï¼‰
    proj_params = [k for k in embedder_keys if "proj" in k or "linear" in k]
    missing_proj = [k for k in proj_params if k not in loaded_embedder_keys]

    if missing_proj:
        print(f"âŒ [CRITICAL] Image Projection weights MISSING! ({len(missing_proj)} params)")
        print(f"   Example missing: {missing_proj[:3]}")
        print("   -> ç”»åƒã®ç‰¹å¾´é‡ãŒMoshiã®æ¬¡å…ƒã«å¤‰æ›ã•ã‚Œãšã€æ¨è«–ãŒå£Šã‚Œã¾ã™ã€‚")
    else:
        print(f"âœ… Image Projection weights loaded ({len(proj_params)} params).")

    # (B) MoshiVis ã® Cross-Attention ã¨ Gate
    # ãƒ¢ãƒ‡ãƒ«ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã‚’å–å¾—
    moshi_keys = set(moshi_vis.lm_model.state_dict().keys())
    loaded_moshi_keys = set(model_state.keys())

    # ãƒã‚§ãƒƒã‚¯å¯¾è±¡: Cross-Attention ã¨ Gate
    target_keywords = ["cross_attention", "gate", "xa"]
    important_params = [k for k in moshi_keys if any(x in k for x in target_keywords)]
    
    missing_important = [k for k in important_params if k not in loaded_moshi_keys]

    if missing_important:
        print(f"âŒ [CRITICAL] Cross-Attention/Gate weights MISSING! ({len(missing_important)} params)")
        print(f"   Example missing: {missing_important[:-1]}")
        print("   -> ãƒ¢ãƒ‡ãƒ«ã¯ç”»åƒæƒ…å ±ã‚’ç„¡è¦–ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ç”Ÿæˆã—ã¾ã™ã€‚")
    else:
        print(f"âœ… Cross-Attention & Gate weights loaded ({len(important_params)} params).")

    print("---------------------------------------\n")

    return moshi_vis.to(dtype), image_embedder.to(dtype)


def get_moshi_vis_train(
    kyuteye_config: KyuteyeConfig,
    moshivis_weight: Optional[str] = None,
    device: str | torch.device = "cpu",
    dtype: torch.dtype = torch.float32,
    strict: bool = False,
    freeze_backbone: bool = True
) -> Tuple[MoshiVis, ImageProjection]:
    """
    å­¦ç¿’ç”¨ã« MoshiVis ãƒ¢ãƒ‡ãƒ«ã¨ ImageProjection ã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°ã€‚

    Args:
        kyuteye_config (KyuteyeConfig): MoshiVis ã®è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        moshi_weight (Optional[str]): safetensors å½¢å¼ã®é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
        device (str | torch.device): ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã€‚
        dtype (torch.dtype): ãƒ‡ãƒ¼ã‚¿å‹ã€‚å­¦ç¿’æ™‚ã¯ float32 æ¨å¥¨ã€‚
        strict (bool): load_state_dict ã® strict ãƒ¢ãƒ¼ãƒ‰ã€‚

    Returns:
        Tuple[MoshiVis, ImageProjection]: ãƒ¢ãƒ‡ãƒ«æœ¬ä½“ã¨ç”»åƒåŸ‹ã‚è¾¼ã¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
    """

    # --- ã‚¹ãƒ†ãƒ¼ãƒˆåˆ†é›¢ç”¨ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒª ---
    image_proj_state: Dict[str, torch.Tensor] = {}
    model_state: Dict[str, torch.Tensor] = {}

    if moshivis_weight is not None:
        print(f"ğŸ”¹ Loading pretrained weights from {moshivis_weight}")
        weights = load_file(moshivis_weight, device="cpu")

        for key, v in weights.items():
            if key.startswith("image_prefix."):
                image_proj_state[key[len("image_prefix."):]] = v
            else:
                # =========================================================
                # â˜… ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: Cross-Attention/Gate ã®é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰é™¤å¤–
                # =========================================================
                # "cross_attention" ãŒã‚­ãƒ¼ã«å«ã¾ã‚Œã‚‹å ´åˆï¼ˆGateã‚‚ã“ã‚Œã«å«ã¾ã‚Œã‚‹æ§‹æˆãŒä¸€èˆ¬çš„ï¼‰
                # è¾æ›¸ã«è¿½åŠ ã›ãšã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã“ã¨ã§ã€ã“ã‚Œã‚‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ãƒ‰ã•ã‚Œãšã€
                # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æ™‚ã®å€¤ï¼ˆãƒ©ãƒ³ãƒ€ãƒ  or ã‚¼ãƒ­åˆæœŸåŒ–ï¼‰ãŒç¶­æŒã•ã‚Œã¾ã™ã€‚
                if "cross_attention" in key:
                    # ãƒ‡ãƒãƒƒã‚°ç”¨ã«æœ€åˆã®æ•°å€‹ã ã‘ãƒ­ã‚°ã«å‡ºã—ã¦ã‚‚è‰¯ã„
                    # print(f"Skipping init for: {key}") 
                    continue

                model_state[key] = v

    print("ğŸ” Num image_prefix params:", len(image_proj_state))
    print(f"ğŸ” Model params to load: {len(model_state)} (Cross-Attention excluded)")

    # --- ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ ---
    # ã“ã“ã§ __init__ ãŒèµ°ã‚Šã€Cross-Attentionã‚„Gateã¯ãƒ©ãƒ³ãƒ€ãƒ (ã¾ãŸã¯0)ã§åˆæœŸåŒ–ã•ã‚Œã‚‹
    moshi_vis = MoshiVis(**kyuteye_config.moshi_constructor_kwargs, dtype=dtype)

    # --- é‡ã¿ãƒ­ãƒ¼ãƒ‰ ---
    if model_state:
        # Cross-Attentionã®ã‚­ãƒ¼ãŒ model_state ã«ç„¡ã„ãŸã‚ã€missing_keys ã«å«ã¾ã‚Œã‚‹ã“ã¨ã«ãªã‚‹
        # strict=False ãªã®ã§ã‚¨ãƒ©ãƒ¼ã«ã¯ãªã‚‰ãªã„
        missing, unexpected = moshi_vis.load_state_dict(model_state, strict=False)

        # æœŸå¾…é€šã‚Š cross_attention ãŒ missing ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèª
        ca_missing = [k for k in missing if "cross_attention" in k]
        print("âœ… MoshiVis loaded.")
        print(f"   - Total Missing: {len(missing)}")
        print(f"   - Cross-Attention Missing (As Expected): {len(ca_missing)}")
        print(f"   - Unexpected: {len(unexpected)}")

    if image_proj_state:
        image_embedder = ImageProjection.from_config(
            kyuteye_config, moshi_vis.llm.dim, image_proj_state, device
        )

    # ----------------------------------------------------
    # 3. Freeze / unfreeze strategy
    # ----------------------------------------------------
    if freeze_backbone:
        print("ğŸ”’ Applying selective fine-tune: cross-attn only.")

        trainable_count = 0
        for name, param in moshi_vis.named_parameters():
            if "llm.transformer.layers" in name and (
                "cross_attention" in name or
                "norm_cross" in name or
                "gate" in name
            ):
                param.requires_grad = True
                trainable_count += 1
            else:
                param.requires_grad = False

        # ImageProjection fully frozen
        image_embedder.train()

        embedder_trainable_count = 0
        for name, p in image_embedder.named_parameters():
            # "enc" (SigLIPãªã©ã®ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³) ã¯å‡çµ
            if "enc." in name:
                p.requires_grad = False
            # ãã‚Œä»¥å¤– (proj_xa, norm_xa ç­‰) ã¯å­¦ç¿’ã•ã›ã‚‹
            else:
                p.requires_grad = True
                embedder_trainable_count += 1

        print(f"ğŸ”¥ Trainable params count: Moshi(CA)={trainable_count}, Embedder(Proj)={embedder_trainable_count}")

        print("ğŸ˜ Initializing Cross-Attention weights to handle large inputs...")
        for name, p in moshi_vis.named_parameters():
            if "cross_attention" in name and "weight" in name and p.requires_grad:
                if "in_proj" in name or "out_proj" in name or "linear" in name:
                    torch.nn.init.normal_(p, mean=0.0, std=0.02)
            if "cross_attention" in name and "bias" in name and p.requires_grad:
                torch.nn.init.constant_(p, 0.0)

        # =========================================================
        # Gateãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¼ãƒ­åˆæœŸåŒ– (Zero Initialization)
        # =========================================================
        print("ğŸ§¹ Initializing Gate parameters with small weights...")
        for name, p in moshi_vis.named_parameters():
            if "gate" in name and p.requires_grad:
                # é‡ã¿(weight)ã¯å°‘ã—å€¤ã‚’æŒãŸã›ã‚‹
                if "weight" in name:
                    torch.nn.init.normal_(p, mean=0.0, std=0.01)

    else:
        # freeze_backbone=False ã®å ´åˆã¯å…¨å­¦ç¿’
        print("ğŸŸ¢ Full fine-tuning enabled (all params trainable).")
        moshi_vis.train()
        image_embedder.train()

    # --- ãƒ¢ãƒ¼ãƒ‰è¨­å®š ---
    moshi_vis.train()
    image_embedder.eval()

    return moshi_vis.to(dtype=dtype), image_embedder.to(dtype=dtype)