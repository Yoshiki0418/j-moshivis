import os
import torch
from accelerate import Accelerator
import hydra
from omegaconf import DictConfig
from accelerate import dispatch_model
from accelerate.utils import infer_auto_device_map
from huggingface_hub import hf_hub_download
import sentencepiece as spm
from moshi.models.loaders import get_mimi
from .models.loaders import get_moshi_vis_train
from .datasets.interleaver import InterleavedTokenizer, Interleaver
from .datasets.data_loader import build_data_loader
from .distributed import get_rank, get_world_size
from .config.kyuteye_config import KyuteyeConfig
from .trainer import JmoshiVisTrainer
from torch.optim import AdamW
from jmoshivis.tools import WandBMetricsWriter


@hydra.main(version_base=None, config_path="../configs", config_name="config")
def main(args: DictConfig):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    accelerator = Accelerator(mixed_precision="bf16")
    kyuteye_config = KyuteyeConfig.from_yml("/workspace/j-moshivis/configs/j-moshi-vis.yaml")

    # --- Tokenizer / Processor ---
    tokenizer = spm.SentencePieceProcessor()
    tokenizer.load("/workspace/j-moshivis/jmoshivis/tokenizer_spm_32k_3.model")

    print("Loading Mimi and MoshiVis...")
    mimi_weight = hf_hub_download(
        repo_id=args.repo_id,
        filename=args.mimi_name,
    )
    mimi = get_mimi(mimi_weight, device)
    mimi.eval()
    for p in mimi.parameters():
        p.requires_grad = False

    print("Start get_moshi_vis_train")
    moshi_vis, image_embedder = get_moshi_vis_train(
        kyuteye_config=kyuteye_config,
        moshivis_weight="/workspace/j-moshivis/model_merged_bf16.safetensors",
        device=device,
        dtype=torch.bfloat16,
        strict=False,
        freeze_backbone=True,
    )

    interleaver = Interleaver(
        tokenizer,
        mimi.frame_rate,
        moshi_vis.text_padding_token_id,
        moshi_vis.end_of_text_padding_id,
        moshi_vis.zero_token_id,
        keep_main_only=True,
        device=device,
    )
    interleaved_tokenizer = InterleavedTokenizer(
        mimi, interleaver, duration_sec=args.duration_sec
    )

    # 5. Load data loaders
    """
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ğŸ§  DataLoader æ§‹æˆæ¦‚è¦ï¼ˆJ-MoshiVisï¼‰
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ãƒ»æœ¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€Interleaverï¼ˆéŸ³å£°ãƒ»ãƒ†ã‚­ã‚¹ãƒˆçµ±åˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ï¼‰ã‚’ä»‹ã—ã¦ã€
    MoshiVis ãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

    ãƒ»å‡ºåŠ›ã¯ `Batch` ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚Šã€
    ä»¥ä¸‹ã®2ã¤ã®ä¸»æ§‹æˆã‚’æŒã¡ã¾ã™ï¼š

        Batch(
            codes: torch.Tensor,                # é‡å­åŒ–ã‚³ãƒ¼ãƒ‰åˆ— [B, D, T]
            condition_attributes: Optional[...] # è£œåŠ©æ¡ä»¶ï¼ˆä¾‹: ç”»åƒç‰¹å¾´ã‚„ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæƒ…å ±ï¼‰
        )

    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ğŸ“¦ Shape specification
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - codes: Tensor of shape [B, D, T]
        B : Batch size
            â””â”€ å„ã‚¹ãƒ†ãƒƒãƒ—ã§ä¸¦åˆ—å‡¦ç†ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
        D : Depth axis
            â””â”€ Residual Quantizerï¼ˆRQï¼‰å±¤ã®æ•°
            ä¾‹: Mimiã§ã¯17å±¤ï¼ˆ=17ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ï¼‰ã‚’ä½¿ç”¨
        T : Time axis
            â””â”€ éŸ³å£°ã‚’ä¸€å®šãƒ•ãƒ¬ãƒ¼ãƒ å¹…ã§åˆ†å‰²ã—ãŸç³»åˆ—é•·
            ä¾‹: ç´„125ã‚¹ãƒ†ãƒƒãƒ— â‰’ 10ç§’å‰å¾Œã®éŸ³å£°é•·

    ä¾‹:
        >>> batch.codes.shape
        torch.Size([2, 17, 125])
        â†’ 2ã‚µãƒ³ãƒ—ãƒ« / å„ã‚µãƒ³ãƒ—ãƒ«17å±¤ / 125ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ—
    """
    target_len = int(mimi.frame_rate * args.duration_sec)
    data_loader = build_data_loader(
        instruct_tokenizer=interleaved_tokenizer,
        args=args.data,
        batch_size=args.train.batch_size,
        seed=args.train.seed,
        rank=get_rank(),  # DDP rank
        world_size=get_world_size(),  # DDP world_size
        is_eval=False,
        image_root=args.data.image_root,
        image_embedder=image_embedder,
        device=device,
        mode="mixed",
        text_tokenizer=tokenizer,
        target_len=target_len
    )

    # # --- 1. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ç”Ÿæˆå¾Œã«1ãƒãƒƒãƒã ã‘å–ã‚Šå‡ºã™ ---
    # data_iter = iter(data_loader)
    # first_batch = next(data_iter)

    # print("=== Batch object ===")
    # print(type(first_batch))
    # print(first_batch)

    # # --- 2. ä¸­èº«ã‚’è¦ç´ ã”ã¨ã«ç¢ºèª ---
    # if hasattr(first_batch, "codes"):
    #     print("\n[Shape] codes:", first_batch.codes.shape)
    #     if first_batch.condition_attributes:
    #         print("[Type] condition_attributes:", type(first_batch.condition_attributes))
    #         print("[Count] len(condition_attributes):", len(first_batch.condition_attributes))
    #         print("[Sample 0] condition_attributes[0]:", first_batch.condition_attributes[0])
    # else:
    #     # ã‚‚ã—Batchã‚¯ãƒ©ã‚¹ã§ãªãlistå½¢å¼ã®ã¾ã¾ãªã‚‰ã“ã¡ã‚‰
    #     print("\nFirst element sample keys:", first_batch[0].keys())
    #     print("First element sample detail:\n", first_batch[0])

    cross_attn_params = []
    gate_params = []
    # other_params ã¯ä»Šå›ç©ºã«ãªã‚‹ã®ãŒç†æƒ³ã§ã™ãŒã€å¿µã®ãŸã‚æ®‹ã—ã¾ã™
    other_params = []

    for name, p in moshi_vis.named_parameters():
        if not p.requires_grad:
            continue

        # ã€ä¿®æ­£1ã€‘ å…ˆã« Gate ã‚’åˆ¤å®šã™ã‚‹ (åå‰ã« "cross_attention" ãŒå«ã¾ã‚Œã¦ã„ã¦ã‚‚ Gate ã¨ã—ã¦æ‰±ã†ãŸã‚)
        if "gate" in name or "xa_gate" in name:
            gate_params.append(p)

        # ã€ä¿®æ­£2ã€‘ norm_cross ã‚‚ CrossAttention ã‚°ãƒ«ãƒ¼ãƒ—ã«å«ã‚ã‚‹
        elif "cross_attention" in name or "xa" in name or "norm_cross" in name:
            cross_attn_params.append(p)

        else:
            # ã“ã“ã«å‡ºã‚‹ã‚‚ã®ãŒãªã‘ã‚Œã°OK
            print("[WARN] Unexpected trainable param:", name)
            other_params.append(p)

    embedder_params = [p for p in image_embedder.parameters() if p.requires_grad]

    print(f"Trainable params: CrossAttn={len(cross_attn_params)}, Gate={len(gate_params)}, Embedder={len(embedder_params)}")

    def print_trainable_parameters(model, model_name="Model"):
        print(f"\n=== Trainable Parameters in {model_name} ===")
        total_params = 0
        for name, param in model.named_parameters():
            if param.requires_grad:
                num_params = param.numel()
                total_params += num_params
                print(f"{name}: {num_params:,} params | Shape: {list(param.shape)}")
        print(f"--- Total Trainable Params in {model_name}: {total_params:,} ---\n")
        return total_params

    # MoshiVisæœ¬ä½“ã®å­¦ç¿’å¯¾è±¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    moshi_params = print_trainable_parameters(moshi_vis, "MoshiVis (Adapters)")

    # ImageEmbedderã®å­¦ç¿’å¯¾è±¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    embedder_params_count = print_trainable_parameters(image_embedder, "ImageEmbedder (Projection)")

    print(f"ğŸ”¥ Grand Total Trainable Parameters: {moshi_params + embedder_params_count:,}")

    # ã‚‚ã— other_params ã«ä½•ã‹æ®‹ã£ã¦ã„ãŸã‚‰ã€ãã‚Œã‚‚å­¦ç¿’å¯¾è±¡ã«åŠ ãˆã‚‹ã¹ãã§ã™ãŒã€
    # ä¸Šè¨˜ã®ä¿®æ­£ã§ norm_cross ã¯ CrossAttn ã«å…¥ã‚‹ãŸã‚ã€åŸºæœ¬çš„ã«ã¯ç©ºã«ãªã‚‹ã¯ãšã§ã™ã€‚

    optimizer = torch.optim.AdamW(
        [
            {"params": cross_attn_params, "lr": 1e-5, "weight_decay": 0.0},
            {"params": gate_params,       "lr": 1e-6, "weight_decay": 0.01},
            {"params": embedder_params,   "lr": 1e-5, "weight_decay": 0.0},
            # å¿…è¦ãªã‚‰ {"params": other_params, ...}
        ],
        fused=True
    )

    # DDPæº–å‚™
    moshi_vis, image_embedder, optimizer, data_loader = accelerator.prepare(
        moshi_vis, image_embedder, optimizer, data_loader
    )

    writer = WandBMetricsWriter(project_name="J-MoshiVis-Training",
                                model_name="j-moshivis")

    # --- Trainer Setup ---
    trainer = JmoshiVisTrainer(moshi_vis, optimizer, device, args.trainer, accelerator, image_embedder=image_embedder, writer=writer, tokenizer=tokenizer)

    # --- Training ---
    epochs = 3
    for epoch in range(1, epochs + 1):
        trainer.train_epoch(data_loader, epoch)

    # --- Save ---
    save_dir = "./checkpoints"
    os.makedirs(save_dir, exist_ok=True)
    torch.save(moshi_vis.state_dict(), f"{save_dir}/jmoshivis_dummy.pt")
    print(f"ğŸ’¾ Saved model to {save_dir}/jmoshivis_dummy.pt")


if __name__ == "__main__":
    main()
