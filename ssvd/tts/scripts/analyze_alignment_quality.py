"""
Script: analyze_alignment_quality_v3.py
Purpose:
    JSONLãƒ•ã‚¡ã‚¤ãƒ«å†…ã®Whisperã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨ã€
    å…ƒãƒ‡ãƒ¼ã‚¿('dialogue.json')ã®ã€Œã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ç™ºè©±ã‚’æ¯”è¼ƒã—ã€
    CERã‚’ç®—å‡ºã™ã‚‹ã€‚ï¼ˆæ—¥æœ¬èªãƒ©ãƒ™ãƒ« "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ" å¯¾å¿œç‰ˆï¼‰
"""

import json
import argparse
import os
import sys
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

def levenshtein_distance(s1, s2):
    """ãƒ¬ãƒ¼ãƒ™ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³è·é›¢ï¼ˆç·¨é›†è·é›¢ï¼‰"""
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)
    if len(s2) == 0:
        return len(s1)
    previous_row = range(len(s2) + 1)
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    return previous_row[-1]

def calculate_cer(reference, hypothesis):
    """CER (Character Error Rate)"""
    # ç©ºç™½ãƒ»å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»ã—ã¦æ­£è¦åŒ–
    ref = reference.replace(" ", "").replace("ã€€", "")
    hyp = hypothesis.replace(" ", "").replace("ã€€", "")
    
    if len(ref) == 0:
        return 1.0 if len(hyp) > 0 else 0.0
    
    dist = levenshtein_distance(ref, hyp)
    return dist / len(ref)

def reconstruct_text_from_alignments(alignments):
    """
    alignmentsãƒªã‚¹ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¨ã¦çµåˆã—ã¦å¾©å…ƒã™ã‚‹
    """
    if not alignments:
        return ""
    
    text_parts = []
    for item in alignments:
        token = item.get("token", "")
        # ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®é™¤å»
        token = token.replace("â–", "")
        text_parts.append(token)
    
    return "".join(text_parts)

def reconstruct_assistant_text_from_dialogue(dialogue_data):
    """
    dialogue.jsonã‹ã‚‰ 'ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ' ã®ç™ºè©±ã®ã¿ã‚’çµåˆã—ã¦å–å¾—ã™ã‚‹
    """
    if not dialogue_data or "dialogue" not in dialogue_data:
        return ""
    
    text_parts = []
    for turn in dialogue_data["dialogue"]:
        speaker = turn.get("speaker", "")
        # â˜…ä¿®æ­£: æ—¥æœ¬èªã®ã€Œã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã«å¯¾å¿œ
        if speaker in ["ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", "assistant", "system", "model", "ai", "gpt"]:
            text = turn.get("text", "")
            text_parts.append(text)
    
    return "".join(text_parts)

def main():
    parser = argparse.ArgumentParser(description="Analyze Alignment Quality (CER/WER) - V3")
    parser.add_argument("--input", default="/workspace/data/speech/train_data_refined_a.jsonl", help="Path to JSONL file.")
    parser.add_argument("--src-prefix", default="/gpu-server/user/yoshiki/j-moshivis", help="Source path prefix to replace.")
    parser.add_argument("--dst-prefix", default="/workspace", help="Destination path prefix.")
    parser.add_argument("--output-img", default="cer_distribution_v3.png", help="Output image filename.")
    
    args = parser.parse_args()

    print(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {args.input} ...")
    
    if not os.path.exists(args.input):
        print(f"âŒ Error: File not found at {args.input}")
        return

    cer_scores = []
    error_samples = []
    valid_count = 0
    missing_files = 0
    no_assistant_text = 0
    
    HIGH_CER_THRESHOLD = 0.3 

    with open(args.input, "r", encoding="utf-8") as f:
        lines = f.readlines()

    print(f"ğŸ” Analyzing {len(lines)} samples (Target: 'ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ')...")

    for line in tqdm(lines):
        try:
            data = json.loads(line)
            
            # 1. Alignments (Hypothesis)
            if "alignments" not in data:
                continue
            hyp_text = reconstruct_text_from_alignments(data["alignments"])
            
            # 2. Dialogue.json (Reference)
            if "path" not in data:
                continue
            
            audio_path = data["path"]
            json_path = audio_path.replace("stereo_dialogue.wav", "dialogue.json")
            
            # ãƒ‘ã‚¹è§£æ±º
            final_json_path = json_path
            if not os.path.exists(final_json_path):
                if args.src_prefix in json_path:
                    replaced_path = json_path.replace(args.src_prefix, args.dst_prefix, 1)
                    if os.path.exists(replaced_path):
                        final_json_path = replaced_path
            
            if not os.path.exists(final_json_path):
                missing_files += 1
                continue

            with open(final_json_path, "r", encoding="utf-8") as df:
                dialogue_data = json.load(df)
                ref_text = reconstruct_assistant_text_from_dialogue(dialogue_data)

            if not ref_text:
                no_assistant_text += 1
                continue

            # 3. CERè¨ˆç®—
            cer = calculate_cer(ref_text, hyp_text)
            cer_scores.append(cer)
            valid_count += 1

            if cer > HIGH_CER_THRESHOLD:
                error_samples.append({
                    "path": final_json_path,
                    "cer": cer,
                    "ref_len": len(ref_text),
                    "hyp_len": len(hyp_text),
                    "ref_sample": ref_text[:50] + "...",
                    "hyp_sample": hyp_text[:50] + "..."
                })

        except json.JSONDecodeError:
            continue
        except Exception:
            continue

    if valid_count == 0:
        print("âš ï¸ æœ‰åŠ¹ãªæ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        print("   (ãƒ’ãƒ³ãƒˆ: dialogue.json ã® speaker ãŒ 'ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ' ä»¥å¤–ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™)")
        return

    # --- çµ±è¨ˆåˆ†æ ---
    avg_cer = np.mean(cer_scores)
    median_cer = np.median(cer_scores)
    max_cer = np.max(cer_scores)
    std_cer = np.std(cer_scores)
    
    perfect = sum(1 for c in cer_scores if c == 0.0)
    excellent = sum(1 for c in cer_scores if 0.0 < c <= 0.05)
    good = sum(1 for c in cer_scores if 0.05 < c <= 0.15)
    bad = sum(1 for c in cer_scores if c > 0.30)

    print("\n" + "="*60)
    print(f"ğŸ“Š ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå“è³ªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« V3 (Japanese Fixed)")
    print("="*60)
    print(f"ğŸ“ åˆ†æå¯¾è±¡æ•°       : {valid_count:,} ä»¶")
    if no_assistant_text > 0:
        print(f"â„¹ï¸  Asstç™ºè©±ãªã—     : {no_assistant_text:,} ä»¶")
    
    print("-" * 60)
    print(f"ğŸ“‰ å…¨ä½“å¹³å‡ CER     : {avg_cer:.2%} (ä½ã„ã»ã©è‰¯ã„)")
    print(f"ğŸ¯ ä¸­å¤®å€¤ CER       : {median_cer:.2%}")
    print(f"Ïƒ  æ¨™æº–åå·®         : {std_cer:.2f}")
    
    print("-" * 60)
    print("ğŸ“‹ å“è³ªåˆ†å¸ƒ:")
    print(f"  âœ¨ å®Œå…¨ä¸€è‡´ (0%)    : {perfect:,} ä»¶ ({perfect/valid_count:.1%})")
    print(f"  ğŸŸ¢ é«˜å“è³ª (0-5%)    : {excellent:,} ä»¶ ({excellent/valid_count:.1%})")
    print(f"  ğŸŸ¡ è‰¯   å¥½ (5-15%)  : {good:,} ä»¶ ({good/valid_count:.1%})")
    print(f"  ğŸ”´ å´©   å£Š (>30%)   : {bad:,} ä»¶ ({bad/valid_count:.1%})")

    if error_samples:
        print("-" * 60)
        print("ğŸš¨ ãƒ¯ãƒ¼ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ä¾‹ (CER > 30%):")
        sorted_errors = sorted(error_samples, key=lambda x: x['cer'], reverse=True)[:3]
        for i, err in enumerate(sorted_errors):
            print(f"\n  [{i+1}] CER: {err['cer']:.2%} | Path: {os.path.basename(err['path'])}")
            print(f"      Ref: {err['ref_sample']}")
            print(f"      Hyp: {err['hyp_sample']}")

    print("="*60)

    # --- ã‚°ãƒ©ãƒ• ---
    print(f"ğŸ“ˆ ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆä¸­: {args.output_img}")
    plt.figure(figsize=(10, 6))
    plt.hist(cer_scores, bins=50, color='lightgreen', edgecolor='black', range=(0, 1.0))
    plt.title('Distribution of Assistant CER (Fixed)')
    plt.xlabel('CER (0.0 = Perfect, 1.0 = Bad)')
    plt.ylabel('Count')
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    
    stats_text = f"Mean: {avg_cer:.3f}\nMedian: {median_cer:.3f}"
    plt.text(0.95, 0.95, stats_text, transform=plt.gca().transAxes, 
             fontsize=12, verticalalignment='top', horizontalalignment='right',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    plt.tight_layout()
    plt.savefig(args.output_img)
    print("Done.")

if __name__ == "__main__":
    main()